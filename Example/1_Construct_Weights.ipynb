{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example weightGIS\n",
    "\n",
    "In this file we are going to be constructing the weights to be used for weighting regional data on places that change\n",
    "over time. Let's take a fictional island nation that has three core regions where one of the three expands its borders \n",
    "sometime between 1931-51. We also for this example have the underlying city administrative regions from 1921 with the \n",
    "population of these regions, so we have the ability to do area and population weighting. \n",
    "\n",
    "If you want to look an image of what this location looks like you can see the image [here][im]. If you want to follow \n",
    "along all the example data is in a folder on the [github page][repo] under ExampleData. This will include all the \n",
    "results as well as the raw data you need to follow along. **However**, keep in mind that this directory includes results\n",
    "from all the tutorials so, so don't worry about the files not mentioned yet!\n",
    "\n",
    "[im]: https://github.com/sbaker-dev/weightGIS/blob/master/Example/Images/ExampleChanges.png"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construct base weights\n",
    "\n",
    "First you will want to make a project folder, in our case its called ExampleData on github. Within it you will want\n",
    "to put all the shapes you want to compare in folder called \"Shapefiles\"; or tell ConstructWeights the name of the folder\n",
    "by setting the keyword arg shape_file_folder_name. \n",
    "\n",
    "You also need to put a population shapefile in the project directory,not the shapefile directory, if you want to do \n",
    "population sub weighting and set a weight index for the base zero column index that holds the population information in \n",
    "this population shapefile. For example, if you have population number for your sub_unit population figures in column 3 \n",
    "(base zero indexing), then you need to provided the weight_index of 3.\n",
    "\n",
    "The GID (numeric name of the place) and the name are by default set to be the 0 and 1 indexes of your shapefiles. You\n",
    "can change these if that is not the case for your data to the column they are within, but this column must be the same \n",
    "index across all shapefiles. \n",
    "\n",
    "In larger datasets you may have names that are not unique, this is what the GID is for, but you may also have a dataset\n",
    "specific clarified such as a place type. For example you may have rural or urban places with a classier in another \n",
    "column. If you want to maintain this information, you can set the index of this column to name_class; but we are not \n",
    "using that within this tutorial series. \n",
    "\n",
    "To see when the changes occur we will be using the ConstructWeights class, to do this we need to compare a set of \n",
    "shapefiles and see if a polygon stays the same in the next iteration of that place in time. We will undertake this \n",
    "process in the following cell. As in this case most of the indexes are set to there default values but remember to set \n",
    "them if your attributes are not the default values. \n",
    "\n",
    "[repo]: https://github.com/sbaker-dev/weightGIS/Example/ExampleData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from weightGIS import ConstructWeights\n",
    "from weightGIS import AdjustWeights\n",
    "\n",
    "project_directory = \"ExampleData\"\n",
    "base_shape = \"1951.shp\"\n",
    "population_shape = \"1921.shp\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1 / 3\n",
      "2 / 3\n",
      "3 / 3\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ConstructWeights(project_directory, base_shape, population_shape, weight_index=2).construct_base_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The differences between area and population\n",
    "\n",
    "This will construct a json file called BaseWeights_0.txt within a folder called BaseWeights within your project folder.\n",
    "Lets look specifically at Ecanlor 1931 before it changes; shown below. As you can see Ecanlor does gains a large \n",
    "amount of Danlhigh based on the area. However, as this area represents mostly open mountains and grass land the actual \n",
    "population that have been re-assigned is drastically different as few people lived in these rural areas. This example \n",
    "has been constructed to be an extreme case, but should allow you to see how if the area's that are transferred are \n",
    "large, but not with an equivalently large amount of population living in it, that area weights may be a poor choice. \n",
    "In general, the larger the geographical generalisation you use, the more dangerous area weights become.\n",
    "\n",
    "*Ecanlor 1931 from within BaseWeights*\n",
    "```json\n",
    "{\n",
    "    \"1__Ecanlor\": {\n",
    "        \"Area\": 100.0,\n",
    "        \"Population\": 100.0\n",
    "    },\n",
    "    \"3__Danlhigh\": {\n",
    "        \"Area\": 41.76016134968026,\n",
    "        \"Population\": 1.8336986193489935\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "## Determine Changes\n",
    "\n",
    "Now we know that a change occurs, but we don't know exactly when it occurs, all we know know is that it occurs between \n",
    "our observed periods in the shapefiles of 1931 and 1951. In this case we have a small number of changes we could see\n",
    "by eye, but in larger numbers and size shapefiles we will need output all the changes we need to find dates for. We can\n",
    "do this via the via the write_out_changes command. In this case you just need to provide the path to file you just \n",
    "created. We can just save the information to our working directory."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Written out changes!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "weights_path = f\"{project_directory}/BaseWeights/BaseWeights_0.txt\"\n",
    "AdjustWeights(project_directory, weights_path).write_out_changes(\"ChangeLog\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assigning dates\n",
    "From ChangeLog we can see both Ecanlor and Dalhigh experience a change so we now need to go and find out when this \n",
    "occurs. Let's say we dig through the archives and find that during 1931 and 1951 there we actually two changes, even \n",
    "though we where only expecting 1. This is an important time to bring up another limitation of *observable changes*. When\n",
    "we use shapefiles we only see the cumulative effect off all the changes, and can only act upon these observed changes.\n",
    "\n",
    "So, lets say the first change happened in 1938, and then we have another change in 1939. We observe the 1939 shape so\n",
    "unless you construct a fix. In larger projects or in areas of the distant past you may not always be able to find \n",
    "reliable information on what the interim changes look like, so you may have to accept some of these changes are dropped\n",
    "from your analysis. In this example, the 1938 date will be dropped as we cannot observe this weight based on the\n",
    "data you have provided. Whether you want to go out of your way to record the changes that will not be used or not is up\n",
    "to you, although it can be important for transparency so it is recommend. \n",
    "\n",
    "This means that you will produce a file that looks as like the following, which can be seen in the Weight_Dates.csv. We \n",
    "will now proceed having dropped this information, but will cover how to fix this problem afterwards\n",
    "\n",
    "| GID         | Place Name | Changes1    | Changes2    |\n",
    "|:------------|:-----      |:-----       |:-----       |\n",
    "| 1           | Ecanlor    | 01/04/1938  | 01/04/1939  |\n",
    "| 2           | Nirghol    | -           | -           |\n",
    "| 3           | Danlhigh   | 01/04/1938  | 01/04/1939  |\n",
    "\n",
    "\n",
    "## Constructed weighted Database\n",
    "\n",
    "For now, we want to take these weights and construct a database that has the weights relative to the dates that places\n",
    "change over time in as is. First we need to load the weights be generated in the ConstructWeights and the dates we \n",
    "constructed in Weight_Dates.csv. These will then be used to assign the weights to these dates. \n",
    "\n",
    "It may be the case that you only observe the dates of a census in a general year format, but the changes you have are \n",
    "more specific in terms of year-month-day. If this is the case, you need to adjust the year format by assigning a month \n",
    "and day to the assign_weights call method so we can look at changes occurring between them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from weightGIS import AssignWeights\n",
    "\n",
    "dates_path = f\"{project_directory}/Weight_Dates.csv\"\n",
    "AssignWeights(weights_path, project_directory, \"1951_weights_by_dates\", dates_path\n",
    "              ).assign_weights_dates(\"0401\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Output\n",
    "This will write out a json database for each ID and place showing when the changes occur starting from the first census\n",
    "year provided. As we can see in the json data below, each place in our reference shape that now has dates assigned to \n",
    "each change, and the places involved in that change in the form of change place id, Change place name, and a given \n",
    "weight that was specified.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"1__Ecanlor\": {\n",
    "        \"19310401\": {\n",
    "            \"1__Ecanlor\": 100.0,\n",
    "            \"3__Danlhigh\": 1.8336986193489935\n",
    "        },\n",
    "        \"19390401\": {\n",
    "            \"1__Ecanlor\": 100.0\n",
    "        }\n",
    "    },\n",
    "    \"2__Nirghol\": {\n",
    "        \"19310401\": {\n",
    "            \"2__Nirghol\": 100.0\n",
    "        }\n",
    "    },\n",
    "    \"3__Danlhigh\": {\n",
    "        \"19310401\": {\n",
    "            \"3__Danlhigh\": 98.16443083327889\n",
    "        },\n",
    "        \"19390401\": {\n",
    "            \"3__Danlhigh\": 100.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correcting for un-observed changes\n",
    "\n",
    "If you want to ensure you get each change, then this can be done by drawing additional shapefiles in between each \n",
    "change. For example, lets say Ecanlor gained part of Danlhigh in 1938, and then the rest of the observed change in 1939. \n",
    "If you are working in a large shapefile with 100's or even thousands of places, it is recommend that you slice out \n",
    "the area of the changes you need to fix as we can update the master database without having to rerun it. So in this case\n",
    "we just isolate Ecanlor and Danlhigh from the shapefile as Nirghol isn't affected.\n",
    "\n",
    "Once you have your area to fix, you would need to find the borders of the shapefile in 1938 and draw that as a new \n",
    "shapefile. In our example case you would create a new folder 'Ecanlor' with shapefiles for this fix in 1931, 1938, and \n",
    "then 1951.This way we can observe all changes. An example of these shapefiles has been placed within 'Ecanlor' to give \n",
    "you an idea of how to structure this change. One you have made the change you can run the process of constructing the \n",
    "weights again"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1 / 2\n",
      "2 / 2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "base_shape = \"1951.shp\"\n",
    "ConstructWeights(project_directory, base_shape, population_shape, weight_index=2, \n",
    "                 shape_file_folder_name=\"Ecanlor\").construct_base_weights()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adjusting the weights\n",
    "\n",
    "This will produce a file called Ecanlor_1.txt in our BaseWeights folder. What we can now do is adjusted our original \n",
    "BaseWeights to have this additional information. For the purpose of this tutorial i have duplicated and then renamed the\n",
    "file to BaseWeights_Adjusted.txt so that we have  a clear before and after. We can then use AdjustWeights as shown below\n",
    "where say specifically which places we want to update via the 'update' list. Each update is handled individually so\n",
    "run this method via a for loop. \n",
    "\n",
    "You can then re-run AssignWeights, but by changing the weights_path to the new file, and see the differences would be.\n",
    "This double change is only used for this example to show how to fix it, and will not be reflected in future tutorials\n",
    "so it is not included within the example data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Adjusted Weights\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "update = [\"1__Ecanlor\", \"3__Danlhigh\"]\n",
    "fixed_path = f\"{project_directory}/BaseWeights/Ecanlor_1.txt\"\n",
    "for ud in update:\n",
    "    AdjustWeights(f\"{project_directory}/BaseWeights\", f\"{project_directory}/BaseWeights/BaseWeights_Adjusted.txt\"\n",
    "                  ).replace_assigned_weight(fixed_path, ud)\n",
    "print(\"Adjusted Weights\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### End of tutorial 1\n",
    "\n",
    "From this you now have your assigned weights, but now we want to actually use them to weight some data. The next step\n",
    "that we will need to do is create a geographic lookup so that we can converge all data to a single unique entry that we\n",
    "can use."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}