{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example weightGIS\n",
    "\n",
    "In this case let's use a working example of how this whole process may be undertaken. Let's take a fictional island \n",
    "nation that has three core regions where one of the three expands its borders sometime between 1931-51. We also for this\n",
    "example have the underlying city administrative regions from 1921 with the population of these regions, so we have the\n",
    "ability to do area and population weighting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://github.com/sbaker-dev/weightGIS/Example/Images/ExampleChanges.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construct base weights\n",
    "\n",
    "If you want to follow along all the example data is in a folder on the [github page][repo] under ExampleData. This will \n",
    "include all the results as well as the raw data you need to follow along. To start with we need to see when changes \n",
    "occur, to do this we need to compare a set of shapefiles and see if a polygon stays the same in the next iteration of \n",
    "that place in time. You need to provide a working directory with a folder called \"Shapefiles\" with all the shapefiles\n",
    "you want to compare in; or later tell ConstructWeights the name of the folder by setting the keyword arg \n",
    "shape_file_folder_name.\n",
    "\n",
    "You also need to put a population shapefile in the project directory, not the shapefile directory, if you want to do\n",
    "population sub weighting and set a weight index for the base zero column index that holds the population information. We\n",
    "will undertake this process in this example. IN this case most of the indexes are set to there default values but \n",
    "remember to set them, like weight index has been set for our subunit attribute column index, if your attributes are not\n",
    "the default values. \n",
    "\n",
    "[repo]: https://github.com/sbaker-dev/weightGIS/Example/ExampleData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from weightGIS import ConstructWeights\n",
    "\n",
    "project_directory = r\"ASSIGN A PATH HERE\"\n",
    "base_shape = \"1951.shp\"\n",
    "population_shape = \"1921.shp\"\n",
    "\n",
    "ConstructWeights(project_directory, base_shape, population_shape, weight_index=2).construct_base_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see whilst Ecanlor does gain a large amount of Danlhigh, it represents mostly open mountains and grass land \n",
    "so the actual population that have been re-assigned is drastically different as few people lived in these rural areas. \n",
    "This example has been constructed to be an extreme case, but should allow you to see how if the area's that are \n",
    "transferred are large, but not with an equivalently large amount of population living in it, that area weights may be a \n",
    "poor choice. In general, the larger the geographical generalisation you use, the more dangerous area weights become.\n",
    "\n",
    "## Determine Changes\n",
    "\n",
    "Now we know that a change occurs between Ecanlor and we have the weight change, but we don't know exactly when it\n",
    "occurs, we simply know it occurs between this period. To assign this value to a date we need to write out all the \n",
    "changes for the user which can be done via the write out changes command. In this case you just need to provide the path\n",
    "to file you just created. We can just save the information to our working directory. Given in this case our unit's did\n",
    "not have a class, then we need to set name_class to be False."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from weightGIS.AssignWeights import AssignWeights\n",
    "\n",
    "AssignWeights(\"BaseWeights_0.txt\", project_directory, \"ChangeLog\").write_out_changes()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see both Ecanlor and Dalhigh both experience a change so we now need to go and find out when this occurs. This\n",
    "is an important time to bring up another limitation of *observable changes*. Let's say we dig through the archives and \n",
    "find that during 1931 and 1951 there we actually two changes, even though we where only expecting 1. When we use \n",
    "shapefiles we only see the cumulative effect off all the changes, and can only act upon these observed changes. Clearly,\n",
    "if you can find mapping information on these individual changes then its possible to correct this by drawing new \n",
    "shapefiles, but this is unlikely to be possible for larger projects on time budgets alone, let alone practically or data\n",
    "limitations. \n",
    "\n",
    "## Determine when the changes occur\n",
    "\n",
    "So, lets say the first change happened in 1938, and then we have another change in 1939. The change that reflects the new\n",
    "shape we observed in 1939 occurs in 1939, so that is the date that will be assigned. Whether you want to go out of your\n",
    "way to record the changes that will not be used or not is up to you, although it can be important for transparency so it\n",
    "is recommend. This means that you will produce a file that looks as like the following, which can be seen in the \n",
    "Weight_Dates.csv\n",
    "\n",
    "| GID         | Place Name | Changes1    | Changes2    |\n",
    "|:------------|:-----      |:-----       |:-----       |\n",
    "| 1           | Ecanlor    | 01/04/1938  | 01/04/1939  |\n",
    "| 2           | Nirghol    | -           | -           |\n",
    "| 3           | Danlhigh   | 01/04/1938  | 01/04/1939  |\n",
    "\n",
    "## Constructed weighted Database\n",
    "\n",
    "Then we want to take these weights and construct a database that has the weights relative to the dates that places\n",
    "change over time in. First we need to load the weights be generated in the ConstructWeights. By default the system will\n",
    "look for a file called Weight_Dates.csv but if you call it something else you will need to update the dates_name keyword\n",
    "argument within AssignWeights. It may be the case that you only observe the dates of a census in a general year format, \n",
    "but the changes you have are more specific in terms of year-month-day. If this is the case, you need to adjust the year\n",
    "format by assigning a month and day to the assign_weights call method so we can look at changes occurring between them.\n",
    "Finally provide a write directory and name, and then your finished!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from weightGIS.AssignWeights import AssignWeights\n",
    "\n",
    "AssignWeights(\"BaseWeights_0.txt\", project_directory, \"1951_weights_by_dates\").assign_weights_dates(\"0401\")\n",
    "\n",
    "Image(url= \"https://github.com/sbaker-dev/weightGIS/Example/Images/jsonView.png\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will write out a json database for each ID and place showing when the changes occur starting from the first census\n",
    "year provided. As we can see in the json data below, each place in our reference shape that now has dates assigned to \n",
    "each change, and the places involved in that change in the form of change place id, Change place name, and a given \n",
    "weight that was specified.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"1__Ecanlor\": {\n",
    "        \"19310401\": {\n",
    "            \"1__Ecanlor\": 100.0,\n",
    "            \"3__Danlhigh\": 1.8336986193489935\n",
    "        },\n",
    "        \"19390401\": {\n",
    "            \"1__Ecanlor\": 100.0\n",
    "        }\n",
    "    },\n",
    "    \"2__Nirghol\": {\n",
    "        \"19310401\": {\n",
    "            \"2__Nirghol\": 100.0\n",
    "        }\n",
    "    },\n",
    "    \"3__Danlhigh\": {\n",
    "        \"19310401\": {\n",
    "            \"3__Danlhigh\": 98.16443083327889\n",
    "        },\n",
    "        \"19390401\": {\n",
    "            \"3__Danlhigh\": 100.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Now that we have these weights, we can now weight time-series data from these regions using just one of the shapefiles.\n",
    "In this case we are going to weight some example in two ways. If you have a very large complex data set or are trying to \n",
    "merge multiple data-sets then it is recommend you create a json database that represents your data. If you are \n",
    "unfamiliar with JSON and want to use a csv, then you can do so as long as you don't mix geo levels within the same \n",
    "document. Places need to be in the first column, with dates running across the top. Dates without data should be left\n",
    "blank. If you are using a json data structure, it needs to take this format:\n",
    " \n",
    "```json\n",
    "{\n",
    "    \"Geo-level1\": {\n",
    "        \"PlaceName\": {\n",
    "            \"AttributeA\": {\n",
    "                \"Dates\": [],\n",
    "                \"Values\": []\n",
    "            },\n",
    "            \"AttributeB\": {\n",
    "                \"Dates\": [],\n",
    "                \"Values\": []\n",
    "            },\n",
    "            \"AttributeC\": {\n",
    "                \"Dates\": [],\n",
    "                \"Values\": []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"Geo-level2\": {\n",
    "        \"PlaceName\": {\n",
    "            \"AttributeA\": {\n",
    "                \"Dates\": [],\n",
    "                \"Values\": []\n",
    "            }\n",
    "        },\n",
    "        \"PlaceName2\": {\n",
    "            \"AttributeA\": {\n",
    "                \"Dates\": [],\n",
    "                \"Values\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "You need to structure your data in a manner that is geo-level specific. For example if you have state level and district\n",
    "level data they both need their own group. Even if you only have 1 level, you **must** group the data by that level.\n",
    "From there you need to assign unique places, that have unique attributes otherwise they will override each other due to\n",
    "how json works. Place names need be ID__NAME in that format specifically. You can have additional information in the \n",
    "name, and ID isn't very human readable which goes against the principle of json, but you must make sure that the ID\n",
    "is the first element as it will be extract by .split(\"__\")[0] with the rest of the information discarded. If you want\n",
    "the place name to be assigned, make sure to have an attribute within the PlaceName that is assigned the name. \n",
    "\n",
    "\n",
    "# Adjacent Polygons\n",
    "\n",
    "It is also it extract an adjacent polygon relation via AdjacentRelations. This looks for common points in shapes within\n",
    "your shapefile and then creates a link json file based on the record index you want."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}